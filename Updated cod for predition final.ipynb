{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b91778-5628-4b9d-ab7d-455f76fe8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyttsx3\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image, ImageStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9272d617-6a48-4c8b-b6ab-7cbb52fe1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32fcd45-65a4-4718-a624-c864511a47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path):\n",
    "    # Normalize the image path by replacing single backslashes with double backslashes\n",
    "    image_path = image_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    \n",
    "    # Load the image\n",
    "    img = image.load_img(image_path, target_size=(128, 128))  # Resize to match model input size\n",
    "    img_array = image.img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize the image\n",
    "\n",
    "    # Load the model (assuming the model is already trained and saved)\n",
    "    model_path = r\"D:\\Revature\\P1\\28-8-24\\model_final.h5\"\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = model.predict(img_array)\n",
    "\n",
    "    # Convert prediction to class label\n",
    "    class_label = 1 if prediction[0] > 0.5 else 0\n",
    "    class_name = 'Real' if class_label == 1 else 'Fake'\n",
    "    \n",
    "    # Generate the explanation\n",
    "    explanation = generate_explanation(class_name, image_path)\n",
    "    \n",
    "    # Speak the results\n",
    "    speak(f\"The image was classified as {class_name}.\")\n",
    "    speak(explanation)\n",
    "    \n",
    "    # Plot the image\n",
    "    plot_image(image_path)\n",
    "    \n",
    "    return class_name, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db683cc5-c514-4187-bf2f-6ab4b9448d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(class_name, image_path):\n",
    "    # Load the image using PIL for analysis\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Check the number of color channels\n",
    "    if img.mode == 'L':  # 'L' mode means grayscale\n",
    "        image_type = \"black and whi`te\"\n",
    "    else:\n",
    "        # Convert image to RGB to ensure we analyze color data properly\n",
    "        img_rgb = img.convert('RGB')\n",
    "        # Get pixel data\n",
    "        pixels = np.array(img_rgb)\n",
    "        # Check if all three channels are the same for each pixel\n",
    "        if np.all(pixels[..., 0] == pixels[..., 1]) and np.all(pixels[..., 1] == pixels[..., 2]):\n",
    "            image_type = \"black and white\"\n",
    "        else:\n",
    "            image_type = \"color\"\n",
    "\n",
    "    # Calculate the average brightness to infer fairness\n",
    "    stat = ImageStat.Stat(img)\n",
    "    brightness = stat.mean[0]\n",
    "\n",
    "    # Set thresholds for determining fairness\n",
    "    if brightness > 150:\n",
    "        fairness = \"fair\"\n",
    "    elif brightness > 100:\n",
    "        fairness = \"medium\"\n",
    "    else:\n",
    "        fairness = \"dark\"\n",
    "\n",
    "    # Combine all information into an explanation\n",
    "    explanation = (\n",
    "        f\"The image was classified as {class_name}. \"\n",
    "        f\"It appears to be a {image_type} image. \"\n",
    "        f\"The detected face has a {fairness} complexion.\"\n",
    "    )\n",
    "\n",
    "    # Additional explanation based on classification\n",
    "    if class_name == \"Real\":\n",
    "        explanation += \" The image contains natural textures and lighting patterns.\"\n",
    "    else:\n",
    "        explanation += \" The image shows signs of being artificially generated, with unusual pixel patterns and lighting.\"\n",
    "\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09bcfb8-a1f8-4bcb-a061-5699ee95a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_path):\n",
    "    # Load and plot the image\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.title('Classified Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b8c278-b2d5-4878-9bf9-ba472a8a667b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_image_path_from_user():\n",
    "    # Ask the user for input\n",
    "    user_input = input(\"Please enter the sentence containing the image path: \")\n",
    "    \n",
    "    # Use regex to find the path in the input sentence\n",
    "    match = re.search(r'(?:[a-zA-Z]:\\\\(?:[^\\\\\\n]+\\\\)*[^\\\\\\n]*\\.(?:jpg|jpeg|png|bmp))', user_input)\n",
    "    if match:\n",
    "        image_path = match.group(0)\n",
    "        # Replace single backslashes with double backslashes\n",
    "        image_path = image_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        return image_path\n",
    "    else:\n",
    "        print(\"No valid image path found in the input.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bfa0d6f-3895-4d7e-ae62-6a89c613c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "image_path = get_image_path_from_user()\n",
    "if image_path:\n",
    "    class_name, explanation = classify_image(image_path)\n",
    "    print(f\"Predicted class: {class_name}\")\n",
    "    print(f\"Explanation: {explanation}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e57229-24c9-4f12-8bb2-23688870d6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdab341-4e5b-4e1d-ad3d-9b711f4bcd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
